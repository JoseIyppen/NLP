{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "ca467fb1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk\n",
    "from nltk.cluster.util import cosine_distance\n",
    "from nltk.corpus import stopwords\n",
    "import numpy as np\n",
    "import networkx as nx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "id": "d4bd388a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# To read the text from the file and remove non-alphabetic characters.\n",
    "\n",
    "def read_article(filename):\n",
    "    file=open(filename,\"r\")\n",
    "    filedata=file.readlines()\n",
    "    article=filedata[0].split(\". \") # creates a list of individual sentences\n",
    "    sen=[]\n",
    "    for s in article:\n",
    "        sen.append(s.replace(\"[^a-zA-Z]\", \" \").split(\" \")) # split each sentence to list of words\n",
    "    sen.pop() #remove the last element(probably invalid sentence)\n",
    "    return sen\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "6fa8fb60",
   "metadata": {},
   "outputs": [],
   "source": [
    "#To find the similarity between two sentenses\n",
    "\n",
    "def sentence_simil(sent1,sent2,stopwords=None):\n",
    "    if stopwords==None:\n",
    "        stopwords=[]\n",
    "    sent1=[w.lower() for w in sent1]\n",
    "    sent2=[w.lower() for w in sent2]\n",
    "    all_words=list(set(sent1+sent2))\n",
    "    vect1=[0]*len(all_words)\n",
    "    vect2=[0]*len(all_words)\n",
    "    for w in sent1:\n",
    "        if w in stopwords:\n",
    "            continue\n",
    "        vect1[all_words.index(w)]+=1\n",
    "    for w in sent2:\n",
    "        if w in stopwords:\n",
    "            continue\n",
    "        vect2[all_words.index(w)]+=1\n",
    "    return 1-cosine_distance(vect1, vect2)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "abe1db45",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate a similarity measure.\n",
    "\n",
    "def gen_sim_matrix(sentences, stopwords):\n",
    "    sim_matrix=np.zeros((len(sentences),len(sentences)))\n",
    "    for i in range(len(sentences)):\n",
    "        for j in range(len(sentences)):\n",
    "            if i==j :\n",
    "                continue\n",
    "            sim_matrix[i][j]=sentence_simil(sentences[i],sentences[j],stopwords)\n",
    "    return sim_matrix\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "id": "35dfd73c",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "def gen_summary(filename, topn=5):\n",
    "    stop_words=stopwords.words('english')\n",
    "    summarize_text=[]\n",
    "    sentences=read_article(filename)\n",
    "    sen_sim=gen_sim_matrix(sentences, stop_words)\n",
    "    sen_sim_graph=nx.from_numpy_array(sen_sim) # In the resulting graph, each sentence is represented as a node,\n",
    "    #and the edges between nodes represent the similarity between sentences. The weight of each edge corresponds \n",
    "    # to the similarity score.\n",
    "    scores=nx.pagerank(sen_sim_graph) #Each node is assigned a PageRank score, indicating its importance within the graph.\n",
    "    ranked_sen=sorted(((scores[i],s) for i,s in enumerate(sentences)), reverse=True)\n",
    "    for i in range(topn):\n",
    "        summarize_text.append(\" \".join(ranked_sen[i][1]))\n",
    "    print(\"Summary: \\n\", \". \".join(summarize_text))\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "id": "0842f4a1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Summary: \n",
      " This is where the data is processed for presentation in an easy-to-consume manner to the right audience for the right purpose. Data visualization is the last step in the data life cycle. The right visualization requires an understanding of the consumerâ€™s needs, nature of the data, and the many tools and techniques available to present data\n"
     ]
    }
   ],
   "source": [
    "gen_summary(\"test.txt\",3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d9e5fa52",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4ee6db45",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "id": "fe685006",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fcbbad7c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a1cf5ca8",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
